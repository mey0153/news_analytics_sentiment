{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of News Headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- Import data\n",
    "- Initial data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News Category Dataset\n",
    "\n",
    "This dataset contains around 200k news headlines from the year 2012 to 2018 obtained from HuffPost. The model trained on this dataset could be used to identify tags for untracked news articles or to identify the type of language used in different news articles.\n",
    "\n",
    "Applications of deep learning for text data:\n",
    "\n",
    "Document classification\n",
    "Articles lebelling\n",
    "Sentiment analysis\n",
    "Author identification\n",
    "Question-answering\n",
    "Language detection\n",
    "Translation Tasks\n",
    "\n",
    "Sources: \n",
    "- [News Category Dataset](https://www.kaggle.com/datasets/rmisra/news-category-dataset?resource=download)\n",
    "- [[NLP]News_articles_classif (Wordembeddings&RNN)](https://www.kaggle.com/code/avikumart/nlp-news-articles-classif-wordembeddings-rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sreed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sreed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sreed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sreed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\sreed\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "# NLTK module\n",
    "import nltk   # nltk module\n",
    "nltk.download('punkt')    # download tokenizers\n",
    "nltk.download('stopwords')    # download stopwords\n",
    "nltk.download('wordnet')    # download wordnet\n",
    "nltk.download('averaged_perceptron_tagger')    # download perceptron tagger\n",
    "nltk.download('maxent_ne_chunker')    # download chunker\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize    # tokenizers\n",
    "from nltk.corpus import stopwords    # stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# Import Stemmers\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "import re    # Regular expressions\n",
    "\n",
    "# Import Pandas, Numpy, pickle and os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pk\n",
    "import os    # For reading the titles of files\n",
    "# Import warning and ignore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Import beautiful soup\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import unicodedata\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data\n",
    "Types of import scenarios:\n",
    "- Reading simple JSON from a local file\n",
    "- Reading simple JSON from a URL\n",
    "- Flattening nested list from JSON object\n",
    "- Flattening nested list and dict from JSON object\n",
    "- Extracting a value from deeply nested JSON\n",
    "\n",
    "Sources:\n",
    "- [How to convert JSON into a Pandas DataFrame](https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>authors</th>\n",
       "      <th>link</th>\n",
       "      <th>short_description</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRIME</td>\n",
       "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
       "      <td>Melissa Jeltsen</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
       "      <td>She left her husband. He killed their children...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
       "      <td>Andy McDonald</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
       "      <td>Of course it has a song.</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
       "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
       "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
       "      <td>Ron Dicker</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
       "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
       "      <td>2018-05-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                           headline  \\\n",
       "0          CRIME  There Were 2 Mass Shootings In Texas Last Week...   \n",
       "1  ENTERTAINMENT  Will Smith Joins Diplo And Nicky Jam For The 2...   \n",
       "2  ENTERTAINMENT    Hugh Grant Marries For The First Time At Age 57   \n",
       "3  ENTERTAINMENT  Jim Carrey Blasts 'Castrato' Adam Schiff And D...   \n",
       "4  ENTERTAINMENT  Julianna Margulies Uses Donald Trump Poop Bags...   \n",
       "\n",
       "           authors                                               link  \\\n",
       "0  Melissa Jeltsen  https://www.huffingtonpost.com/entry/texas-ama...   \n",
       "1    Andy McDonald  https://www.huffingtonpost.com/entry/will-smit...   \n",
       "2       Ron Dicker  https://www.huffingtonpost.com/entry/hugh-gran...   \n",
       "3       Ron Dicker  https://www.huffingtonpost.com/entry/jim-carre...   \n",
       "4       Ron Dicker  https://www.huffingtonpost.com/entry/julianna-...   \n",
       "\n",
       "                                   short_description       date  \n",
       "0  She left her husband. He killed their children... 2018-05-26  \n",
       "1                           Of course it has a song. 2018-05-26  \n",
       "2  The actor and his longtime girlfriend Anna Ebe... 2018-05-26  \n",
       "3  The actor gives Dems an ass-kicking for not fi... 2018-05-26  \n",
       "4  The \"Dietland\" actress said using the bags is ... 2018-05-26  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "# File path\n",
    "file = r'D:\\Project\\News_Analytics\\news_analytics_sentiment\\data\\raw\\archive\\News_Category_Dataset_v2.json'\n",
    "\n",
    "# Read file\n",
    "with open(file, 'r'):\n",
    "    df = pd.read_json(file, lines=True)\n",
    "\n",
    "# View\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Properties\n",
    "- The size and shape of the dataset. \n",
    "- Data issues\n",
    "- Unique authors\n",
    "- Uniques categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200853 entries, 0 to 200852\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   category           200853 non-null  object        \n",
      " 1   headline           200853 non-null  object        \n",
      " 2   authors            200853 non-null  object        \n",
      " 3   link               200853 non-null  object        \n",
      " 4   short_description  200853 non-null  object        \n",
      " 5   date               200853 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(5)\n",
      "memory usage: 9.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Dataframe information\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200853 6\n"
     ]
    }
   ],
   "source": [
    "# Dataframe shape\n",
    "nrows, ncols = df.shape\n",
    "print(nrows, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIME' 'ENTERTAINMENT' 'WORLD NEWS' 'IMPACT' 'POLITICS' 'WEIRD NEWS'\n",
      " 'BLACK VOICES' 'WOMEN' 'COMEDY' 'QUEER VOICES' 'SPORTS' 'BUSINESS'\n",
      " 'TRAVEL' 'MEDIA' 'TECH' 'RELIGION' 'SCIENCE' 'LATINO VOICES' 'EDUCATION'\n",
      " 'COLLEGE' 'PARENTS' 'ARTS & CULTURE' 'STYLE' 'GREEN' 'TASTE'\n",
      " 'HEALTHY LIVING' 'THE WORLDPOST' 'GOOD NEWS' 'WORLDPOST' 'FIFTY' 'ARTS'\n",
      " 'WELLNESS' 'PARENTING' 'HOME & LIVING' 'STYLE & BEAUTY' 'DIVORCE'\n",
      " 'WEDDINGS' 'FOOD & DRINK' 'MONEY' 'ENVIRONMENT' 'CULTURE & ARTS'] \n",
      " 41\n",
      "['Melissa Jeltsen' 'Andy McDonald' 'Ron Dicker' ...\n",
      " 'Courtney Garcia, Contributor\\nI tell stories and drink wine.'\n",
      " 'Mateo Gutierrez, Contributor\\nArtist'\n",
      " 'John Giacobbi, Contributor\\nTales from the Interweb by The Web Sheriff'] \n",
      " 27993\n"
     ]
    }
   ],
   "source": [
    "# Unique news categories\n",
    "unique_news_categories = df['category'].unique()\n",
    "print(unique_news_categories, '\\n', len(unique_news_categories))\n",
    "# Number of unique news categories\n",
    "# print(len())\n",
    "\n",
    "# Unique authors\n",
    "unique_authors = df['authors'].unique()\n",
    "print(unique_authors, '\\n', len(unique_authors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('comp814')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "639f47b3ffe9cb0d52a016403724052829c1da1d1ed45c2f9474f7ea5aa43d6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
